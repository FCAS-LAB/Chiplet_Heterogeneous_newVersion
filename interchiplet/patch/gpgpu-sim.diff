diff --git a/libcuda/Makefile b/libcuda/Makefile
index c8ff2e3..81e2f9a 100644
--- a/libcuda/Makefile
+++ b/libcuda/Makefile
@@ -108,7 +108,7 @@ lib$(PROG).a: $(OBJS)
 	ar rcs $(OUTPUT_DIR)/lib$(PROG).a $(OBJS)
 
 $(OUTPUT_DIR)/%.o: %.cc
-	$(CPP) $(CXXFLAGS) -I./ -I$(OUTPUT_DIR) -I$(CUDA_INSTALL_PATH)/include  -c $< -o $@
+	$(CPP) $(CXXFLAGS) -I./ -I$(OUTPUT_DIR) -I$(CUDA_INSTALL_PATH)/include -I$(SIMULATOR_ROOT)/interchiplet/includes -c $< -o $@
 
 $(OUTPUT_DIR)/%.o: %.c
 	$(CPP) $(CCFLAGS) -I./ -I$(OUTPUT_DIR) -I$(CUDA_INSTALL_PATH)/include  -c $< -o $@
diff --git a/libcuda/cuda_runtime_api.cc b/libcuda/cuda_runtime_api.cc
index fd05f55..8b99541 100644
--- a/libcuda/cuda_runtime_api.cc
+++ b/libcuda/cuda_runtime_api.cc
@@ -606,10 +606,10 @@ void **cudaRegisterFatBinaryInternal(void *fatCubin,
     int pos = app_binary_path.find("python");
     if (pos == std::string::npos) {
       // Not pytorch app : checking cuda version
-      int app_cuda_version = get_app_cuda_version();
-      assert(
-          app_cuda_version == CUDART_VERSION / 1000 &&
-          "The app must be compiled with same major version as the simulator.");
+      //int app_cuda_version = get_app_cuda_version();
+      //assert(
+      //    app_cuda_version == CUDART_VERSION / 1000 &&
+      //    "The app must be compiled with same major version as the simulator.");
     }
 
     // int app_cuda_version = get_app_cuda_version();
@@ -7010,3 +7010,105 @@ extern "C" CUresult CUDAAPI cuMemPrefetchAsync_ptsz(CUdeviceptr devPtr,
   printf("WARNING: this function has not been implemented yet.");
   return CUDA_SUCCESS;
 }
+
+#include "apis_cu.h"
+#include "global_define.h"
+#include "pipe_comm.h"
+
+InterChiplet::PipeComm global_pipe_comm;
+
+__host__ cudaError_t CUDARTAPI barrier(int __uid, int __src_x, int __src_y, int __count) {
+    std::cout << "Enter GPGPUSim barrier" << std::endl;
+    // Sync barrier
+    InterChiplet::SyncProtocol::barrierSync(__uid, __src_x, __src_y, __count);
+    // Sync clock.
+    gpgpu_sim* gpu = GPGPU_Context()->the_gpgpusim->the_context->get_device()->get_gpgpu();
+    long long unsigned int timeNow = gpu->gpu_sim_cycle + gpu->gpu_tot_sim_cycle;
+    long long int timeEnd = InterChiplet::SyncProtocol::writeSync(
+        timeNow, __src_x, __src_y, __uid, 0, 1, InterChiplet::SPD_BARRIER + __count);
+    gpu->gpu_tot_sim_cycle = timeEnd - gpu->gpu_sim_cycle;
+    return cudaSuccess;
+}
+
+__host__ cudaError_t CUDARTAPI launchResource(int __dst_x, int __dst_y, int __src_x, int __src_y) {
+    std::cout << "Enter GPGPUSim launchResource" << std::endl;
+    // Sync wait locker.
+    InterChiplet::SyncProtocol::launchSync(__src_x, __src_y, __dst_x, __dst_y);
+    // Sync clock.
+    gpgpu_sim* gpu = GPGPU_Context()->the_gpgpusim->the_context->get_device()->get_gpgpu();
+    long long unsigned int timeNow = gpu->gpu_sim_cycle + gpu->gpu_tot_sim_cycle;
+    long long int timeEnd = InterChiplet::SyncProtocol::writeSync(
+        timeNow, __src_x, __src_y, __dst_x, __dst_y, 1, InterChiplet::SPD_LAUNCHER);
+    gpu->gpu_tot_sim_cycle = timeEnd - gpu->gpu_sim_cycle;
+    return cudaSuccess;
+}
+
+__host__ cudaError_t CUDARTAPI unlockResource(int __dst_x, int __dst_y, int __src_x, int __src_y) {
+    // Sync wait locker.
+    InterChiplet::SyncProtocol::unlockSync(__src_x, __src_y, __dst_x, __dst_y);
+    return cudaSuccess;
+}
+
+__host__ cudaError_t CUDARTAPI waitLauncher(int __dst_x, int __dst_y, int* __src_x, int* __src_y) {
+    std::cout << "Enter GPGPUSim waitLauncher" << std::endl;
+    // Sync wait locker.
+    InterChiplet::SyncProtocol::waitlaunchSync(__src_x, __src_y, __dst_x, __dst_y);
+    // Sync clock.
+    gpgpu_sim* gpu = GPGPU_Context()->the_gpgpusim->the_context->get_device()->get_gpgpu();
+    long long unsigned int timeNow = gpu->gpu_sim_cycle + gpu->gpu_tot_sim_cycle;
+    long long int timeEnd = InterChiplet::SyncProtocol::readSync(
+        timeNow, *__src_x, *__src_y, __dst_x, __dst_y, 1, InterChiplet::SPD_LAUNCHER);
+    gpu->gpu_tot_sim_cycle = timeEnd - gpu->gpu_sim_cycle;
+    return cudaSuccess;
+}
+
+__host__ cudaError_t CUDARTAPI sendMessage(int __dst_x, int __dst_y, int __src_x, int __srx_y,
+                                           void* __addr, int __nbyte) {
+    // Read data from GPU memory.
+    uint8_t* interdata = new uint8_t[__nbyte];
+    cudaMemcpy(interdata, __addr, __nbyte, cudaMemcpyDeviceToHost);
+
+    // write data to chiplet.
+    std::cout << "Enter GPGPUSim sendMessage" << std::endl;
+    // Pipe
+    InterChiplet::SyncProtocol::pipeSync(__src_x, __srx_y, __dst_x, __dst_y);
+    // Write data
+    char* fileName = InterChiplet::SyncProtocol::pipeName(__src_x, __srx_y, __dst_x, __dst_y);
+    global_pipe_comm.write_data(fileName, interdata, __nbyte);
+    delete fileName;
+    // Sync clock.
+    gpgpu_sim* gpu = GPGPU_Context()->the_gpgpusim->the_context->get_device()->get_gpgpu();
+    long long unsigned int timeNow = gpu->gpu_sim_cycle + gpu->gpu_tot_sim_cycle;
+    long long int timeEnd = InterChiplet::SyncProtocol::writeSync(timeNow, __src_x, __srx_y,
+                                                                  __dst_x, __dst_y, __nbyte, 0);
+    gpu->gpu_tot_sim_cycle = timeEnd - gpu->gpu_sim_cycle;
+    // gpu->chiplet_direct_set_cycle(timeEnd - gpu->gpu_tot_sim_cycle);
+
+    return cudaSuccess;
+}
+
+__host__ cudaError_t CUDARTAPI receiveMessage(int __dst_x, int __dst_y, int __src_x, int __srx_y,
+                                              void* __addr, int __nbyte) {
+    // read data from chiplet.
+    uint8_t* interdata = new uint8_t[__nbyte];
+    std::cout << "Enter GPGPUSim receiveMessage" << std::endl;
+    // Pipe
+    InterChiplet::SyncProtocol::pipeSync(__src_x, __srx_y, __dst_x, __dst_y);
+    // Read data
+    char* fileName = InterChiplet::SyncProtocol::pipeName(__src_x, __srx_y, __dst_x, __dst_y);
+    global_pipe_comm.read_data(fileName, interdata, __nbyte);
+    delete fileName;
+    // Sync clock.
+    gpgpu_sim* gpu = GPGPU_Context()->the_gpgpusim->the_context->get_device()->get_gpgpu();
+    long long unsigned int timeNow = gpu->gpu_sim_cycle + gpu->gpu_tot_sim_cycle;
+    long long int timeEnd = InterChiplet::SyncProtocol::readSync(timeNow, __src_x, __srx_y, __dst_x,
+                                                                 __dst_y, __nbyte, 0);
+    gpu->gpu_tot_sim_cycle = timeEnd - gpu->gpu_sim_cycle;
+    // gpu->chiplet_direct_set_cycle(timeEnd - gpu->gpu_tot_sim_cycle);
+
+    // write data to GPU memory.
+    cudaMemcpy(__addr, interdata, __nbyte, cudaMemcpyHostToDevice);
+    delete interdata;
+
+    return cudaSuccess;
+}
diff --git a/src/gpgpu-sim/gpu-sim.cc b/src/gpgpu-sim/gpu-sim.cc
index 1650688..0eaa4c8 100644
--- a/src/gpgpu-sim/gpu-sim.cc
+++ b/src/gpgpu-sim/gpu-sim.cc
@@ -81,6 +81,10 @@ class gpgpu_sim_wrapper {};
 #define MAX(a, b) (((a) > (b)) ? (a) : (b))
 
 bool g_interactive_debugger_enabled = false;
+// TODO: directly forward GPU cycle.
+bool g_chiplet_directly_set_cycle = false;
+unsigned long long g_chiplet_directly_set_cycle_val = 0;
+bool g_chiplet_jump_deadlock_detect = false;
 
 tr1_hash_map<new_addr_type, unsigned> address_random_interleaving;
 
@@ -1854,6 +1858,14 @@ void gpgpu_sim::cycle() {
       raise(SIGTRAP);  // Debug breakpoint
     }
     gpu_sim_cycle++;
+    // TODO: quick forward cycle.
+    if (g_chiplet_directly_set_cycle)
+    {
+      std::cout << "Directly set cycle to " << g_chiplet_directly_set_cycle_val << std::endl;
+      gpu_sim_cycle = g_chiplet_directly_set_cycle_val;
+      g_chiplet_jump_deadlock_detect = true;
+      g_chiplet_directly_set_cycle = false;
+    }
 
     if (g_interactive_debugger_enabled) gpgpu_debug();
 
@@ -1956,7 +1968,10 @@ void gpgpu_sim::cycle() {
 
     if (!(gpu_sim_cycle % 50000)) {
       // deadlock detection
-      if (m_config.gpu_deadlock_detect && gpu_sim_insn == last_gpu_sim_insn) {
+      if (g_chiplet_jump_deadlock_detect) {
+        g_chiplet_jump_deadlock_detect = false;
+        last_gpu_sim_insn = gpu_sim_insn;
+      } else if (m_config.gpu_deadlock_detect && gpu_sim_insn == last_gpu_sim_insn) {
         gpu_deadlock = true;
       } else {
         last_gpu_sim_insn = gpu_sim_insn;
@@ -2051,3 +2066,10 @@ const shader_core_config *gpgpu_sim::getShaderCoreConfig() {
 const memory_config *gpgpu_sim::getMemoryConfig() { return m_memory_config; }
 
 simt_core_cluster *gpgpu_sim::getSIMTCluster() { return *m_cluster; }
+
+// Directly set cycle
+void gpgpu_sim::chiplet_direct_set_cycle(long long int end_time)
+{
+  g_chiplet_directly_set_cycle_val = end_time;
+  g_chiplet_directly_set_cycle = true;
+}
diff --git a/src/gpgpu-sim/gpu-sim.h b/src/gpgpu-sim/gpu-sim.h
index 2e6820d..5c0ce40 100644
--- a/src/gpgpu-sim/gpu-sim.h
+++ b/src/gpgpu-sim/gpu-sim.h
@@ -565,6 +565,9 @@ class gpgpu_sim : public gpgpu_t {
   // backward pointer
   class gpgpu_context *gpgpu_ctx;
 
+  // Directly set gpu cycle.
+  void chiplet_direct_set_cycle(long long int end_time);
+
  private:
   // clocks
   void reinit_clock_domains(void);
